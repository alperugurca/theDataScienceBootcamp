{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Natural Language Processing with Disaster Tweets\n\nThe Disaster Tweets Classifier is an NLP project using DistilBERT to identify real disaster tweets from Kaggle's competition dataset. The model achieves efficient classification through advanced text preprocessing and fine-tuning techniques. Deployed on Hugging Face Spaces, it provides instant disaster tweet classification through a user-friendly interface.\n\nData: https://www.kaggle.com/competitions/nlp-getting-started/data\n\nModel: https://huggingface.co/alperugurcan/nlp-disaster\n\nHugging Face: https://huggingface.co/spaces/alperugurcan/nlp-disaster","metadata":{}},{"cell_type":"code","source":"!pip install pandas scikit-learn","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:06:12.211045Z","iopub.execute_input":"2024-10-29T15:06:12.211373Z","iopub.status.idle":"2024-10-29T15:06:24.845748Z","shell.execute_reply.started":"2024-10-29T15:06:12.211338Z","shell.execute_reply":"2024-10-29T15:06:24.844509Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1. Preprocessing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:06:24.848072Z","iopub.execute_input":"2024-10-29T15:06:24.848481Z","iopub.status.idle":"2024-10-29T15:06:43.764993Z","shell.execute_reply.started":"2024-10-29T15:06:24.848438Z","shell.execute_reply":"2024-10-29T15:06:43.763981Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ntrain['text'] = train['text'].str.replace(r'http\\S+|[^\\w\\s]', '', regex=True)\ntest['text'] = test['text'].str.replace(r'http\\S+|[^\\w\\s]', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:06:43.766176Z","iopub.execute_input":"2024-10-29T15:06:43.766934Z","iopub.status.idle":"2024-10-29T15:06:43.914979Z","shell.execute_reply.started":"2024-10-29T15:06:43.766886Z","shell.execute_reply":"2024-10-29T15:06:43.914008Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:06:43.917076Z","iopub.execute_input":"2024-10-29T15:06:43.917411Z","iopub.status.idle":"2024-10-29T15:06:46.683737Z","shell.execute_reply.started":"2024-10-29T15:06:43.917378Z","shell.execute_reply":"2024-10-29T15:06:46.682832Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9247e64130dc4b289432400292d752a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"106e8e901e414c60b43566a620895ee6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28996e8431694429aba5b71e9000cbbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96c1dcd2f8214f9980e0ff15d4aa3aab"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d78429949c6c4cc79621e01f0c9effda"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize(texts): \n    return tokenizer(\n        texts, \n        padding='max_length',\n        truncation=True,\n        max_length=128,\n        return_tensors=None\n    )","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:06:46.684876Z","iopub.execute_input":"2024-10-29T15:06:46.685170Z","iopub.status.idle":"2024-10-29T15:06:46.690686Z","shell.execute_reply.started":"2024-10-29T15:06:46.685137Z","shell.execute_reply":"2024-10-29T15:06:46.689616Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset.from_dict({\n    'text': train['text'].tolist(),\n    'labels': train['target'].tolist()\n}).map(lambda x: tokenize(x['text']), batched=True)\n\ntest_dataset = Dataset.from_dict({\n    'text': test['text'].tolist()\n}).map(lambda x: tokenize(x['text']), batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:06:46.691903Z","iopub.execute_input":"2024-10-29T15:06:46.692256Z","iopub.status.idle":"2024-10-29T15:06:47.962008Z","shell.execute_reply.started":"2024-10-29T15:06:46.692216Z","shell.execute_reply":"2024-10-29T15:06:47.961107Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7613 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8a8f3cbf8844119990b447daa1c84a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3263 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f1b1ded82744ab0bd99d6670933dd0d"}},"metadata":{}}]},{"cell_type":"markdown","source":"## 2. Model","metadata":{}},{"cell_type":"code","source":"# Previous code remains the same until training part...\n\n# Optimized training configuration\ntrainer = Trainer(\n    model=model,\n    args=TrainingArguments(\n        output_dir='./results',\n        num_train_epochs=2,                    # Reduced epochs\n        per_device_train_batch_size=32,        # Increased batch size\n        gradient_accumulation_steps=2,         # Add gradient accumulation\n        warmup_ratio=0.1,                      # Add warmup\n        learning_rate=2e-4,                    # Increased learning rate\n        logging_steps=100,                     # Reduced logging frequency\n        report_to=\"none\",\n        fp16=True,                            # Enable mixed precision training\n        dataloader_num_workers=2,             # Enable parallel data loading\n        remove_unused_columns=True,           # Memory optimization\n        no_cuda=False,                        # Ensure GPU usage\n        load_best_model_at_end=False         # Skip validation to save time\n    ),\n    train_dataset=train_dataset\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:06:47.963309Z","iopub.execute_input":"2024-10-29T15:06:47.963614Z","iopub.status.idle":"2024-10-29T15:08:17.222844Z","shell.execute_reply.started":"2024-10-29T15:06:47.963581Z","shell.execute_reply":"2024-10-29T15:08:17.221794Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [238/238 01:26, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.471300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.326200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=238, training_loss=0.37806424373338204, metrics={'train_runtime': 87.5405, 'train_samples_per_second': 173.931, 'train_steps_per_second': 2.719, 'total_flos': 504237152984064.0, 'train_loss': 0.37806424373338204, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## 3. Prediction and Submission","metadata":{}},{"cell_type":"code","source":"preds = np.argmax(trainer.predict(test_dataset).predictions, axis=1)\npd.DataFrame({'id': test['id'], 'target': preds}).to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:14:02.257069Z","iopub.execute_input":"2024-10-29T15:14:02.258024Z","iopub.status.idle":"2024-10-29T15:14:09.931456Z","shell.execute_reply.started":"2024-10-29T15:14:02.257978Z","shell.execute_reply":"2024-10-29T15:14:09.930432Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4. Save model for Hugging Face space","metadata":{}},{"cell_type":"code","source":"output_dir = \"disaster_model\"\ntrainer.save_model(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:17:36.157783Z","iopub.execute_input":"2024-10-29T15:17:36.158211Z","iopub.status.idle":"2024-10-29T15:17:36.769089Z","shell.execute_reply.started":"2024-10-29T15:17:36.158175Z","shell.execute_reply":"2024-10-29T15:17:36.768072Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"('disaster_model/tokenizer_config.json',\n 'disaster_model/special_tokens_map.json',\n 'disaster_model/vocab.txt',\n 'disaster_model/added_tokens.json',\n 'disaster_model/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained('./model')\ntokenizer.save_pretrained('./model')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:22:15.848809Z","iopub.execute_input":"2024-10-29T15:22:15.849220Z","iopub.status.idle":"2024-10-29T15:22:16.460479Z","shell.execute_reply.started":"2024-10-29T15:22:15.849183Z","shell.execute_reply":"2024-10-29T15:22:16.459521Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"('./model/tokenizer_config.json',\n './model/special_tokens_map.json',\n './model/vocab.txt',\n './model/added_tokens.json',\n './model/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"!pip install huggingface_hub\nfrom huggingface_hub import login\n\n# Hugging Face hesabınıza giriş yapın\nlogin()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:27:19.736580Z","iopub.execute_input":"2024-10-29T15:27:19.737006Z","iopub.status.idle":"2024-10-29T15:27:31.122249Z","shell.execute_reply.started":"2024-10-29T15:27:19.736970Z","shell.execute_reply":"2024-10-29T15:27:31.121181Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.8.30)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d24d35172e25410aad5ead611d6ec5a1"}},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import HfApi, create_repo","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:28:29.222379Z","iopub.execute_input":"2024-10-29T15:28:29.222782Z","iopub.status.idle":"2024-10-29T15:28:29.227638Z","shell.execute_reply.started":"2024-10-29T15:28:29.222747Z","shell.execute_reply":"2024-10-29T15:28:29.226648Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"repo_name = \"alperugurcan/nlp-disaster\"\ncreate_repo(repo_name)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:31:09.911700Z","iopub.execute_input":"2024-10-29T15:31:09.912102Z","iopub.status.idle":"2024-10-29T15:31:10.320539Z","shell.execute_reply.started":"2024-10-29T15:31:09.912063Z","shell.execute_reply":"2024-10-29T15:31:10.319607Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"RepoUrl('https://huggingface.co/alperugurcan/nlp-disaster', endpoint='https://huggingface.co', repo_type='model', repo_id='alperugurcan/nlp-disaster')"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import upload_file\n\n# Define the repository name\nrepo_name = \"alperugurcan/nlp-disaster\"  # Replace with your username and desired model name\n\n# Upload the model files\nupload_file(\n    path_or_fileobj=\"/kaggle/working/model/model.safetensors\",  # Path to the file on Kaggle\n    path_in_repo=\"model.safetensors\",  # Path in the repo\n    repo_id=repo_name  # The repo name\n)\n\nupload_file(\n    path_or_fileobj=\"/kaggle/working/model/config.json\",\n    path_in_repo=\"config.json\",\n    repo_id=repo_name\n)\n\nupload_file(\n    path_or_fileobj=\"/kaggle/working/model/special_tokens_map.json\",\n    path_in_repo=\"special_tokens_map.json\",\n    repo_id=repo_name\n)\n\nupload_file(\n    path_or_fileobj=\"/kaggle/working/model/tokenizer.json\",\n    path_in_repo=\"tokenizer.json\",\n    repo_id=repo_name\n)\n\nupload_file(\n    path_or_fileobj=\"/kaggle/working/model/tokenizer_config.json\",\n    path_in_repo=\"tokenizer_config.json\",\n    repo_id=repo_name\n)\n\nupload_file(\n    path_or_fileobj=\"/kaggle/working/model/vocab.txt\",\n    path_in_repo=\"vocab.txt\",\n    repo_id=repo_name\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T15:37:59.334440Z","iopub.execute_input":"2024-10-29T15:37:59.334806Z","iopub.status.idle":"2024-10-29T15:38:13.807547Z","shell.execute_reply.started":"2024-10-29T15:37:59.334774Z","shell.execute_reply":"2024-10-29T15:38:13.806579Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae9c750a6aaa46e186e08d1abaa6e95a"}},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/alperugurcan/nlp-disaster/commit/d285f524bdb4550e57428ede5416686812cb35e3', commit_message='Upload vocab.txt with huggingface_hub', commit_description='', oid='d285f524bdb4550e57428ede5416686812cb35e3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/alperugurcan/nlp-disaster', endpoint='https://huggingface.co', repo_type='model', repo_id='alperugurcan/nlp-disaster'), pr_revision=None, pr_num=None)"},"metadata":{}}]}]}