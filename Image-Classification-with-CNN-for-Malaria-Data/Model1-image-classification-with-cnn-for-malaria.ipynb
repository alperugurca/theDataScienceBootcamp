{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":200743,"sourceType":"datasetVersion","datasetId":87153}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Model 1\n## Malaria Tespiti için Derin Öğrenme Modeli\n","metadata":{}},{"cell_type":"markdown","source":"CNN With Custom Images\n\nThe dataset contains 2 folders\nInfected\nUninfected\nAnd a total of 27,558 images.\n\nPlease get this Dataset from the official NIH Website: https://ceb.nlm.nih.gov/repositories/malaria-datasets/\n\nor\n\nhttps://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:20:29.469242Z","iopub.execute_input":"2024-08-26T19:20:29.469986Z","iopub.status.idle":"2024-08-26T19:20:29.478644Z","shell.execute_reply.started":"2024-08-26T19:20:29.469943Z","shell.execute_reply":"2024-08-26T19:20:29.476833Z"}}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, InputLayer, Reshape, MaxPooling2D, Flatten, Rescaling","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:22:55.853636Z","iopub.execute_input":"2024-08-26T19:22:55.854482Z","iopub.status.idle":"2024-08-26T19:22:55.859430Z","shell.execute_reply.started":"2024-08-26T19:22:55.854432Z","shell.execute_reply":"2024-08-26T19:22:55.858244Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:20:46.158208Z","iopub.execute_input":"2024-08-26T19:20:46.158632Z","iopub.status.idle":"2024-08-26T19:20:46.164633Z","shell.execute_reply.started":"2024-08-26T19:20:46.158593Z","shell.execute_reply":"2024-08-26T19:20:46.163511Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"2.16.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the data directory\ndata_dir = \"/kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images\"\n\n# Load the training dataset\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    data_dir, # Path to the data directory\n    image_size=(128, 128),  # Görüntüleri 128x128 piksel boyutuna yeniden boyutlandır\n    subset='training',\n    batch_size=16,  # Her bir batch'teki görüntü sayısı\n    shuffle=True, # Verileri rastgele karıştır\n    seed=123, # Random seed for reproducibility\n    validation_split=0.2\n)\n\n# Load the validation dataset\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    data_dir, # Path to the data directory\n    image_size=(128, 128),  # Reduced image size\n    subset='validation', # Specify this as the validation dataset\n    batch_size=16,  # Her bir batch'teki görüntü sayısı\n    validation_split=0.2,\n    seed=123 # Random seed for reproducibility\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:20:50.550278Z","iopub.execute_input":"2024-08-26T19:20:50.550735Z","iopub.status.idle":"2024-08-26T19:21:10.662997Z","shell.execute_reply.started":"2024-08-26T19:20:50.550688Z","shell.execute_reply":"2024-08-26T19:21:10.661755Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 27558 files belonging to 2 classes.\nUsing 22047 files for training.\nFound 27558 files belonging to 2 classes.\nUsing 5511 files for validation.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Normalize pixel values between 0 and 1\nnormalization_layer = Rescaling(1./255) # Piksel değerlerini normalleştirmek için Rescaling katmanı\n\ntrain_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Map normalization to images in the training dataset\nval_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:22:59.868686Z","iopub.execute_input":"2024-08-26T19:22:59.869190Z","iopub.status.idle":"2024-08-26T19:22:59.948919Z","shell.execute_reply.started":"2024-08-26T19:22:59.869140Z","shell.execute_reply":"2024-08-26T19:22:59.947694Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    InputLayer(input_shape=(128, 128, 3)),  # Girdi katmanı, görüntülerin boyutunu (128x128 piksel ve 3 renk kanalı) belirtir\n    Conv2D(12, (3, 3), activation=\"relu\"),  # İlk evrişim katmanı, 12 filtre ve 3x3 kernel boyutu ile, ReLU aktivasyon fonksiyonu kullanır\n    MaxPooling2D(pool_size=(2, 2)),  # Max pooling katmanı, görüntüyü küçültmek için 2x2 havuzlama kullanır\n    Conv2D(64, (3, 3), activation=\"relu\"),  # İkinci evrişim katmanı, 64 filtre ve 3x3 kernel boyutu ile, ReLU aktivasyon fonksiyonu kullanır\n    Flatten(),  # Çıktıyı 2 boyutludan 1 boyutlu hale getirir (fully connected layer için)\n    Dense(10, activation=\"relu\"),  # Fully connected katman, 10 nöron ve ReLU aktivasyon fonksiyonu ile\n    Dense(1, activation=\"sigmoid\")  # Çıkış katmanı, 1 nöron ve sigmoid aktivasyon fonksiyonu ile (ikili sınıflandırma için)\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:23:16.905411Z","iopub.execute_input":"2024-08-26T19:23:16.905833Z","iopub.status.idle":"2024-08-26T19:23:16.994311Z","shell.execute_reply.started":"2024-08-26T19:23:16.905795Z","shell.execute_reply":"2024-08-26T19:23:16.993173Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Modeli Adam optimizasyonu, binary crossentropy kaybı ve accuracy metriği ile derle\nmodel.compile(optimizer=\"adam\",  # Adam optimizörü\n              loss=tf.keras.losses.BinaryCrossentropy(),  # Binary crossentropy kaybı (ikili sınıflandırma için)\n              metrics=[\"accuracy\"])  # Eğitim sırasında accuracy metriğini takip et","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:23:32.627996Z","iopub.execute_input":"2024-08-26T19:23:32.628421Z","iopub.status.idle":"2024-08-26T19:23:32.644494Z","shell.execute_reply.started":"2024-08-26T19:23:32.628380Z","shell.execute_reply":"2024-08-26T19:23:32.643046Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"history2 = model.fit(train_ds, # Training dataset\n                     epochs=5, # Number of training epochs\n                     validation_data=val_ds # Validation dataset\n                    )","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:23:40.970089Z","iopub.execute_input":"2024-08-26T19:23:40.970517Z","iopub.status.idle":"2024-08-26T19:38:24.839045Z","shell.execute_reply.started":"2024-08-26T19:23:40.970473Z","shell.execute_reply":"2024-08-26T19:38:24.837648Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m1378/1378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 117ms/step - accuracy: 0.4990 - loss: 0.7408 - val_accuracy: 0.4916 - val_loss: 0.6933\nEpoch 2/5\n\u001b[1m1378/1378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 116ms/step - accuracy: 0.5002 - loss: 0.6932 - val_accuracy: 0.4916 - val_loss: 0.6933\nEpoch 3/5\n\u001b[1m1378/1378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 116ms/step - accuracy: 0.5005 - loss: 0.6932 - val_accuracy: 0.4916 - val_loss: 0.6933\nEpoch 4/5\n\u001b[1m1378/1378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 116ms/step - accuracy: 0.5006 - loss: 0.6932 - val_accuracy: 0.4916 - val_loss: 0.6933\nEpoch 5/5\n\u001b[1m1378/1378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 116ms/step - accuracy: 0.4987 - loss: 0.6932 - val_accuracy: 0.4916 - val_loss: 0.6933\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model on the validation dataset to check its performance\ntest_loss, test_accuracy = model.evaluate(val_ds)  # Evaluate the model on validation data\nprint(f\"Test Loss: {test_loss}\")  # Print the test loss\nprint(f\"Test Accuracy: {test_accuracy}\")  # Print the test accuracy","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:38:28.914503Z","iopub.execute_input":"2024-08-26T19:38:28.914929Z","iopub.status.idle":"2024-08-26T19:38:40.962091Z","shell.execute_reply.started":"2024-08-26T19:38:28.914889Z","shell.execute_reply":"2024-08-26T19:38:40.960766Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.4903 - loss: 0.6933\nTest Loss: 0.6932913661003113\nTest Accuracy: 0.4915623366832733\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}