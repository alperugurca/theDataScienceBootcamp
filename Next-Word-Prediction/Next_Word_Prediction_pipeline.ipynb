{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Next Word Prediction with transformer\n",
        "This code uses the Hugging Face Transformers library to create a text generation model that predicts the next word for a given input text\n",
        "\n",
        "Example Solution: https://thecleverprogrammer.com/2023/07/17/next-word-prediction-model-using-python/\n",
        "\n",
        "Hugging Face: https://huggingface.co/spaces/alperugurcan/next-word-predicter"
      ],
      "metadata": {
        "id": "wz-qyeKwVGRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import re\n",
        "\n",
        "# Create a text generation pipeline using a pre-trained model\n",
        "nwp = pipeline(\"text-generation\")\n",
        "\n",
        "# Define the input text for which we want to predict the next word\n",
        "text = \"Going to go\"\n",
        "\n",
        "# Define a function to generate the next word based on the input text\n",
        "def nextwp(text):\n",
        "    # Use the text generation pipeline to generate text\n",
        "    result = nwp(\n",
        "        text,                   # The input text\n",
        "        max_new_tokens=1,      # Generate only one new token (word)\n",
        "        num_return_sequences=1, # Return only one generated sequence\n",
        "        pad_token_id=50256     # Specify the padding token ID\n",
        "    )\n",
        "\n",
        "    # Extract the generated text from the result\n",
        "    generated_text = result[0]['generated_text']\n",
        "\n",
        "    # Isolate the next word by removing the input text from the generated text\n",
        "    next_word = generated_text[len(text):].strip().split()[0]\n",
        "\n",
        "    # Use a regular expression to check if the next word is valid\n",
        "    if re.match(r'^\\w+$', next_word):\n",
        "        return next_word\n",
        "    else:\n",
        "        return \"Invalid word generated\"\n",
        "\n",
        "# Call the function with the input text and print the predicted next word\n",
        "print(nextwp(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMUCCCP8dqSu",
        "outputId": "738cd2e1-d386-4483-f29f-404c39043c3b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "through\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kLm9XtUsiabJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}