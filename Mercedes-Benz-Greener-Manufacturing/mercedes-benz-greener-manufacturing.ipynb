{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6565,"databundleVersionId":44042,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mercedes-Benz Manufacturing Time Prediction\n\nThis project uses LightGBM regression to predict Mercedes-Benz manufacturing times based on vehicle features. The model processes production data, trains on historical records, and provides real-time predictions through a simple web interface, aiming to optimize manufacturing efficiency.\n\nDataset: https://www.kaggle.com/competitions/mercedes-benz-greener-manufacturing/data\n\nHugging Face: https://huggingface.co/spaces/alperugurcan/time-prediction","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom lightgbm import LGBMRegressor\nimport joblib\n\ndef process_data():\n    train = pd.read_csv('/kaggle/input/mercedes-benz-greener-manufacturing/train.csv.zip')\n    test = pd.read_csv('/kaggle/input/mercedes-benz-greener-manufacturing/test.csv.zip')\n    \n    data = pd.concat([train, test]).set_index('ID')\n    data = pd.get_dummies(data)\n    \n    train_processed = data[:len(train)]\n    test_processed = data[len(train):]\n    \n    return train_processed, test_processed\n\ndef main():\n    train, test = process_data()\n    \n    model = LGBMRegressor(random_state=42)\n    model.fit(train.drop('y', axis=1), train.y)\n    \n    joblib.dump(model, 'mercedes_model.joblib')\n    \n    feature_names = train.drop('y', axis=1).columns.tolist()\n    joblib.dump(feature_names, 'feature_names.joblib')\n    \n    predictions = model.predict(test.drop('y', axis=1))\n    pd.DataFrame({'ID': test.index, 'y': predictions}).to_csv('submission.csv', index=False)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-31T16:46:22.340099Z","iopub.execute_input":"2024-10-31T16:46:22.340617Z","iopub.status.idle":"2024-10-31T16:46:23.059990Z","shell.execute_reply.started":"2024-10-31T16:46:22.340567Z","shell.execute_reply":"2024-10-31T16:46:23.058795Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007684 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 794\n[LightGBM] [Info] Number of data points in the train set: 4209, number of used features: 397\n[LightGBM] [Info] Start training from score 100.669318\n","output_type":"stream"}]}]}