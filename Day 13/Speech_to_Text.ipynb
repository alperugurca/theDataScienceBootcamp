{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Youtube üzerinden ses çekme"
      ],
      "metadata": {
        "id": "v4Mm4pejiwbl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pONZLCwQcVJU",
        "outputId": "47359682-9edb-40e4-c08c-64a3076b710a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytubefix\n",
            "  Downloading pytubefix-6.15.4-py3-none-any.whl.metadata (5.4 kB)\n",
            "Downloading pytubefix-6.15.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytubefix\n",
            "Successfully installed pytubefix-6.15.4\n"
          ]
        }
      ],
      "source": [
        "pip install pytubefix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytubefix import YouTube\n",
        "\n",
        "yt_url = 'https://www.youtube.com/watch?v=jZOywn1qArI'\n",
        "yt = YouTube(yt_url)\n",
        "\n",
        "audio=yt.streams.get_audio_only()\n",
        "audio.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "osongevFcki2",
        "outputId": "f7a974dc-929f-4019-db73-fbe442976f93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Taken Phone Speech [HD].mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY4yogtDdKBy",
        "outputId": "a8fe4e14-a92b-4538-a5ba-fb6e10ab11e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "RiMlEntcfA8Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=whisper.load_model(\"large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRSglGAUfC_7",
        "outputId": "1c51b9f4-46f3-42c8-a6cf-d13a01f21fac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.88G/2.88G [00:30<00:00, 102MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=model.transcribe('liam.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J58qoi4BfQHW",
        "outputId": "02fef8f1-17f1-4ef5-c8ce-e681003583c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video2='https://www.youtube.com/watch?v=uoYEudIl0Ak'\n",
        "data2 = YouTube(video2)\n",
        "\n",
        "audio2=data2.streams.get_audio_only()\n",
        "audio2.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGPJex63gJT5",
        "outputId": "a60c10ce-1d6c-43d4-99ca-b749f0bdb998"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2=model.transcribe('CamdanKalp.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoVR7IT0kWxY",
        "outputId": "57a51dd5-a2fd-41d3-d60b-e692656d51f1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "nhuYJVhAKt5m",
        "outputId": "dda44cb5-0262-4285-8bde-848e4e0aa750"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I don't know who you are. I don't know what you want. If you are looking for ransom, I can tell you I don't have money. But what I do have are a very particular set of skills. Skills I have acquired over a very long career. Skills that make me a nightmare for people like you. If you let my daughter go now, that'll be the end of it. I will not look for you. I will not pursue you. But if you don't, I will look for you. I will find you. And I will kill you. Good luck. you\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "YkuYA9GXKvEs",
        "outputId": "fa094b7a-ec17-4440-d3a3-1d4fcebb3f26"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Yar Senin Hediye Bir Gönül Ağrısı Ah Ölüm Olmalı Yok Aşk Bir Adım Aşk Bizi Terk Etti Ah Ne Gelir Elde Dertli Bağrımda Camdan Bir Kalp Var Artık Dönsen De Geçmez Ki Bu Kırıklar Sen Gittin Yastığımda Kokun Misafir Kaldı Gözlerimden Haylaz Yağmurlar Yaldı Ah Ölüm Olmalı Ayrılık mı Sen mi yoksa Sevda mı Hangisi Sebebim Olur Sen Gittin Yastığımda Kokun Misafir Kaldı Gözlerimden Haylaz Yağmurlar Yaldı Ayrılık mı Sen mi yoksa Sevda mı Hangisi Sebebim Olur Sen Gittin Yastığımda Ah Ne Gelir Elde Dertli Bağrımda Camdan Bir Kalp Var Artık Dönsen De Geçmez Ki Bu Kırıklar Sen Gittin Yastığımda Kokun Misafir Kaldı Dertli Bağrımda Camdan Bir Kalp Var Artık Dönsen De Sevda mı Geçmez Ki Bu Kırıklar Geçmez Ki Bu Kırıklar Sen Gittin Sen Gittin Yastığımda Kokun Misafir Kaldı Kokun Misafir Kaldı Gözlerimden Haylaz Yağmurlar Yaldı Haylaz Yağmurlar Yaldı Ayrılık mı Sen mi yoksa Sevda mı Hangisi Sevda mı Hangisi Sebebim Olur Sen Gittin Sen Gittin Yastığımda Kokun Misafir Kaldı Kokun Misafir Kaldı Gözlerimden Haylaz Yağmurlar Yaldı Haylaz Yağmurlar Yaldı Ayrılık mı Sen mi yoksa Sevda mı Hangisi Sevda mı Sevda�, Sevda Aydın Sevda Aydın Sevda Aydın Sisi Sen Kaldın 36 00P Sen Kaldın www.feyyaz.tv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6SfHniaEK65a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}