{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concrete is the most important material in civil engineering. The concrete compressive strength is a highly nonlinear function of age and ingredients. Measurements for Cement, Blast Furnace Slag, Fly Ash, Water, Superplasticizer,Coarse Aggregate, and Fine Aggregate are all in units of kg / m^3 of concrete mixture. The Age is measured in days. The Concrete Compressive Strength is measured in MPa.\n",
    "\n",
    "These data were downloaded from the UCI Machine Learning Repository ( https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength).\n",
    "\n",
    "The original source of the data is: I-Cheng Yeh, \"Modeling of strength of high performance concrete using artificial neural networks,\" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998).\n",
    "\n",
    "We are building a simple model of the form y=ùõΩ0+ùõΩ1ùë•1+ùõΩ2ùë•2+ùõΩ3ùë•3+ùõΩ4ùë•4+ùõΩ5ùë•5+ùõΩ6ùë•6+ùõΩ7ùë•7+ùõΩ8ùë•8, where:\n",
    "\n",
    "After reading the data, you should use this code to change the column names.\n",
    "\n",
    "df.columns = ['Cement', 'Slag', 'FlyAsh', 'Water', 'Plasticizer', 'CoarseAgg', 'FineAgg', 'Age', 'Strength']\n",
    "\n",
    "x1 is Concrete\n",
    "x2 is Slag\n",
    "x3 is FlyAsh\n",
    "x4 is Water\n",
    "x5 is Plasticizer\n",
    "x6 is CoarseAgg\n",
    "x7 is FineAgg\n",
    "x8 is Age and all of the ùõΩ values are determined by linear regression.\n",
    "Problem 1: Regression\n",
    "\n",
    "Develop a machine learning model that can predict the Concrete Compressive Strength for a particular concrete recipe given the quantities for input ingredients and a number of days (Age) for curing the concrete. This is a baseline model. What we are primarily interested in here is:\n",
    "\n",
    "Making sure that the data is properly formatted for scikit-learn.\n",
    "Identifying and separating features (X) and target (y).\n",
    "Having a base score for the model that we can use to measure progress.\n",
    "Validating that we have enough data for both training and testing.\n",
    "Use at least 7 conventional machine learning algorithms and DEEP LEARNING (Tensorflow - Keras or Pytorch) to predict Concrete Compressive Strength\n",
    "Problem 2: Classification Develop a machine learning model that can predict the ConcreteClass for a particular concrete recipe.\n",
    "\n",
    "Take concrete regression data and modify it to be suitable for classification examples.# create new categorical targets\n",
    "\n",
    "Create new columns using the following functions def green_classifier(s): \"\"\" Use numeric data to create a Green categorical feature. \"\"\"\n",
    "\n",
    "if (s.Slag + s.FlyAsh < 150.0) and (s.Plasticizer < 10.0):\n",
    "    return \"n/a\"\n",
    "else:\n",
    "    return \"green\"\n",
    "def strength_classifer(x): \"\"\" Use numeric data to create a ConcreteClass categorical feature. This is based on \"CIP 35 - Testing Compressive Strength of Concrete\", National Ready Mixed Concrete Association (www.nrmca.org), 2003 & 2014. \"\"\"\n",
    "\n",
    "if x < 17.0:\n",
    "    return \"non-structural\"\n",
    "elif x < 28.0:\n",
    "    return \"residential\"\n",
    "elif x < 70.0:\n",
    "    return \"commercial\"\n",
    "else:\n",
    "    return \"high-strength\"\n",
    "df[\"Green\"] = df.apply(green_classifier, axis=1) df[\"ConcreteClass\"] = df.Strength.apply(strength_classifer)\n",
    "\n",
    "convert Plasticizer to text (the numeric values are embedded in Green)\n",
    "df.Plasticizer = df.Plasticizer.apply(lambda x: \"yes\" if x > 0 else \"no\")\n",
    "\n",
    "remove Strength feature as replaced by categorical target ConcreteClass\n",
    "df.drop(\"Strength\", axis=1, inplace=True)\n",
    "\n",
    "Develop a machine learning model that can predict the ConcreteClass for a particular concrete recipe given the quantities for input ingredients and a number of days (Age) for curing the concrete.\n",
    "\n",
    "This is a baseline model. What we are primarily interested in here is:\n",
    "\n",
    "Making sure that the data is properly formatted for scikit-learn.\n",
    "Identifying and separating features (X) and target (y).\n",
    "Having a base score for the model that we can use to measure progress.\n",
    "Validating that we have enough data for both training and testing.\n",
    "Use at least 7 conventional machine learning algorithms and DEEP LEARNING (Tensorflow - Keras or Pytorch) to predict ConcreteClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 95.9755, R2: 0.6275\n",
      "Decision Tree - MSE: 47.0538, R2: 0.8174\n",
      "Random Forest - MSE: 29.6219, R2: 0.8850\n",
      "SVR - MSE: 88.9783, R2: 0.6547\n",
      "KNN - MSE: 72.4172, R2: 0.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alperugurcan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Deep Learning Regression - MSE: 36.3740, R2: 0.8588\n",
      "Logistic Regression - Accuracy: 0.8058\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.87      0.89      0.88       133\n",
      " high-strength       0.33      0.17      0.22         6\n",
      "non-structural       0.78      0.91      0.84        32\n",
      "   residential       0.59      0.49      0.53        35\n",
      "\n",
      "      accuracy                           0.81       206\n",
      "     macro avg       0.64      0.61      0.62       206\n",
      "  weighted avg       0.79      0.81      0.80       206\n",
      "\n",
      "Decision Tree - Accuracy: 0.8447\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.92      0.91      0.92       133\n",
      " high-strength       1.00      0.50      0.67         6\n",
      "non-structural       0.88      0.72      0.79        32\n",
      "   residential       0.59      0.77      0.67        35\n",
      "\n",
      "      accuracy                           0.84       206\n",
      "     macro avg       0.85      0.72      0.76       206\n",
      "  weighted avg       0.86      0.84      0.85       206\n",
      "\n",
      "Random Forest - Accuracy: 0.8738\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.91      0.95      0.93       133\n",
      " high-strength       1.00      0.33      0.50         6\n",
      "non-structural       0.90      0.84      0.87        32\n",
      "   residential       0.69      0.69      0.69        35\n",
      "\n",
      "      accuracy                           0.87       206\n",
      "     macro avg       0.87      0.70      0.75       206\n",
      "  weighted avg       0.88      0.87      0.87       206\n",
      "\n",
      "SVC - Accuracy: 0.7476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\alperugurcan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.83      0.94      0.88       133\n",
      " high-strength       0.00      0.00      0.00         6\n",
      "non-structural       0.62      0.47      0.54        32\n",
      "   residential       0.44      0.40      0.42        35\n",
      "\n",
      "      accuracy                           0.75       206\n",
      "     macro avg       0.47      0.45      0.46       206\n",
      "  weighted avg       0.71      0.75      0.72       206\n",
      "\n",
      "KNN - Accuracy: 0.7621\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.85      0.92      0.88       133\n",
      " high-strength       0.50      0.17      0.25         6\n",
      "non-structural       0.70      0.59      0.64        32\n",
      "   residential       0.45      0.43      0.44        35\n",
      "\n",
      "      accuracy                           0.76       206\n",
      "     macro avg       0.63      0.53      0.55       206\n",
      "  weighted avg       0.75      0.76      0.75       206\n",
      "\n",
      "Naive Bayes - Accuracy: 0.6602\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.88      0.71      0.78       133\n",
      " high-strength       0.22      0.67      0.33         6\n",
      "non-structural       0.55      0.81      0.66        32\n",
      "   residential       0.35      0.34      0.35        35\n",
      "\n",
      "      accuracy                           0.66       206\n",
      "     macro avg       0.50      0.63      0.53       206\n",
      "  weighted avg       0.72      0.66      0.68       206\n",
      "\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
      "Deep Learning Classification - Accuracy: 0.8544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       133\n",
      "           1       0.67      0.33      0.44         6\n",
      "           2       0.88      0.88      0.88        32\n",
      "           3       0.63      0.69      0.66        35\n",
      "\n",
      "    accuracy                           0.85       206\n",
      "   macro avg       0.77      0.70      0.72       206\n",
      "weighted avg       0.85      0.85      0.85       206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_excel('Concrete_Data.xls')\n",
    "df.columns = ['Cement', 'Slag', 'FlyAsh', 'Water', 'Plasticizer', 'CoarseAgg', 'FineAgg', 'Age', 'Strength']\n",
    "\n",
    "# Regression task\n",
    "X_reg = df.drop('Strength', axis=1)\n",
    "y_reg = df['Strength']\n",
    "\n",
    "# Classification task\n",
    "def green_classifier(s):\n",
    "    if (s.Slag + s.FlyAsh < 150.0) and (s.Plasticizer < 10.0):\n",
    "        return \"n/a\"\n",
    "    else:\n",
    "        return \"green\"\n",
    "\n",
    "def strength_classifer(x):\n",
    "    if x < 17.0:\n",
    "        return \"non-structural\"\n",
    "    elif x < 28.0:\n",
    "        return \"residential\"\n",
    "    elif x < 70.0:\n",
    "        return \"commercial\"\n",
    "    else:\n",
    "        return \"high-strength\"\n",
    "\n",
    "df[\"Green\"] = df.apply(green_classifier, axis=1)\n",
    "df[\"ConcreteClass\"] = df.Strength.apply(strength_classifer)\n",
    "df.Plasticizer = df.Plasticizer.apply(lambda x: \"yes\" if x > 0 else \"no\")\n",
    "df.drop(\"Strength\", axis=1, inplace=True)\n",
    "\n",
    "X_class = pd.get_dummies(df.drop('ConcreteClass', axis=1))\n",
    "y_class = df['ConcreteClass']\n",
    "\n",
    "# Split the data\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_reg_train_scaled = scaler.fit_transform(X_reg_train)\n",
    "X_reg_test_scaled = scaler.transform(X_reg_test)\n",
    "X_class_train_scaled = scaler.fit_transform(X_class_train)\n",
    "X_class_test_scaled = scaler.transform(X_class_test)\n",
    "\n",
    "# Regression models\n",
    "reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'SVR': SVR(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "}\n",
    "\n",
    "for name, model in reg_models.items():\n",
    "    model.fit(X_reg_train_scaled, y_reg_train)\n",
    "    y_pred = model.predict(X_reg_test_scaled)\n",
    "    mse = mean_squared_error(y_reg_test, y_pred)\n",
    "    r2 = r2_score(y_reg_test, y_pred)\n",
    "    print(f\"{name} - MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
    "\n",
    "# Deep Learning Regression model\n",
    "model_reg = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_reg_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model_reg.compile(optimizer='adam', loss='mse')\n",
    "model_reg.fit(X_reg_train_scaled, y_reg_train, epochs=100, batch_size=32, verbose=0)\n",
    "y_pred = model_reg.predict(X_reg_test_scaled)\n",
    "mse = mean_squared_error(y_reg_test, y_pred)\n",
    "r2 = r2_score(y_reg_test, y_pred)\n",
    "print(f\"Deep Learning Regression - MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
    "\n",
    "# Classification models\n",
    "class_models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "}\n",
    "\n",
    "for name, model in class_models.items():\n",
    "    model.fit(X_class_train_scaled, y_class_train)\n",
    "    y_pred = model.predict(X_class_test_scaled)\n",
    "    accuracy = accuracy_score(y_class_test, y_pred)\n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_class_test, y_pred))\n",
    "\n",
    "# Deep Learning Classification model\n",
    "model_class = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_class_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model_class.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_class.fit(X_class_train_scaled, pd.get_dummies(y_class_train).values.argmax(1), epochs=100, batch_size=32, verbose=0)\n",
    "y_pred = model_class.predict(X_class_test_scaled).argmax(1)\n",
    "accuracy = accuracy_score(pd.get_dummies(y_class_test).values.argmax(1), y_pred)\n",
    "print(f\"Deep Learning Classification - Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(pd.get_dummies(y_class_test).values.argmax(1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
